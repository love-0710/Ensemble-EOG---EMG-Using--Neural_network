{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep learning with 2 different dataset and ensemble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 3ms/step - loss: 1.7427 - accuracy: 0.3190 - val_loss: 1.0175 - val_accuracy: 0.7292\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2528 - accuracy: 0.6046 - val_loss: 1.0048 - val_accuracy: 0.7292\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1100 - accuracy: 0.6823 - val_loss: 0.9845 - val_accuracy: 0.7292\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.0644 - accuracy: 0.7022 - val_loss: 0.9576 - val_accuracy: 0.7292\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0548 - accuracy: 0.7045 - val_loss: 0.9492 - val_accuracy: 0.7292\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0362 - accuracy: 0.7122 - val_loss: 0.9740 - val_accuracy: 0.7292\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.0287 - accuracy: 0.7094 - val_loss: 0.9867 - val_accuracy: 0.7292\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0129 - accuracy: 0.7203 - val_loss: 0.9501 - val_accuracy: 0.7292\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0138 - accuracy: 0.7176 - val_loss: 0.9730 - val_accuracy: 0.7292\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0121 - accuracy: 0.7194 - val_loss: 0.9577 - val_accuracy: 0.7292\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9900 - accuracy: 0.7207 - val_loss: 1.0297 - val_accuracy: 0.7292\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9879 - accuracy: 0.7212 - val_loss: 0.9676 - val_accuracy: 0.7292\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9939 - accuracy: 0.7207 - val_loss: 0.9841 - val_accuracy: 0.7292\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9872 - accuracy: 0.7203 - val_loss: 1.0272 - val_accuracy: 0.7292\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.9885 - accuracy: 0.7207 - val_loss: 1.0120 - val_accuracy: 0.7292\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 3ms/step - loss: 2.2126 - accuracy: 0.2725 - val_loss: 1.5249 - val_accuracy: 0.6444\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6437 - accuracy: 0.5061 - val_loss: 1.2916 - val_accuracy: 0.6444\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4633 - accuracy: 0.6014 - val_loss: 1.3135 - val_accuracy: 0.6444\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4169 - accuracy: 0.6186 - val_loss: 1.3136 - val_accuracy: 0.6444\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3953 - accuracy: 0.6245 - val_loss: 1.3003 - val_accuracy: 0.6444\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3954 - accuracy: 0.6290 - val_loss: 1.2962 - val_accuracy: 0.6444\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3694 - accuracy: 0.6394 - val_loss: 1.2933 - val_accuracy: 0.6444\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3535 - accuracy: 0.6412 - val_loss: 1.3019 - val_accuracy: 0.6444\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3401 - accuracy: 0.6493 - val_loss: 1.2942 - val_accuracy: 0.6444\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3266 - accuracy: 0.6525 - val_loss: 1.2910 - val_accuracy: 0.6444\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3208 - accuracy: 0.6507 - val_loss: 1.2899 - val_accuracy: 0.6444\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3129 - accuracy: 0.6521 - val_loss: 1.2924 - val_accuracy: 0.6444\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2967 - accuracy: 0.6521 - val_loss: 1.2903 - val_accuracy: 0.6444\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3042 - accuracy: 0.6530 - val_loss: 1.2909 - val_accuracy: 0.6444\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3000 - accuracy: 0.6534 - val_loss: 1.2916 - val_accuracy: 0.6444\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3102 - accuracy: 0.6539 - val_loss: 1.2894 - val_accuracy: 0.6444\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2894 - accuracy: 0.6539 - val_loss: 1.2937 - val_accuracy: 0.6444\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2796 - accuracy: 0.6539 - val_loss: 1.2904 - val_accuracy: 0.6444\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2904 - accuracy: 0.6539 - val_loss: 1.2892 - val_accuracy: 0.6444\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2928 - accuracy: 0.6539 - val_loss: 1.2905 - val_accuracy: 0.6444\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2917 - accuracy: 0.6539 - val_loss: 1.2878 - val_accuracy: 0.6444\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2899 - accuracy: 0.6539 - val_loss: 1.2881 - val_accuracy: 0.6444\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2834 - accuracy: 0.6539 - val_loss: 1.2898 - val_accuracy: 0.6444\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2901 - accuracy: 0.6539 - val_loss: 1.2882 - val_accuracy: 0.6444\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2857 - accuracy: 0.6539 - val_loss: 1.2883 - val_accuracy: 0.6444\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2856 - accuracy: 0.6539 - val_loss: 1.2917 - val_accuracy: 0.6444\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2868 - accuracy: 0.6539 - val_loss: 1.2888 - val_accuracy: 0.6444\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2824 - accuracy: 0.6539 - val_loss: 1.2893 - val_accuracy: 0.6444\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2787 - accuracy: 0.6539 - val_loss: 1.2879 - val_accuracy: 0.6444\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2758 - accuracy: 0.6539 - val_loss: 1.2913 - val_accuracy: 0.6444\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2811 - accuracy: 0.6539 - val_loss: 1.2902 - val_accuracy: 0.6444\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "df=pd.read_excel('EOGsignal.xlsx').iloc[:, 1:]\n",
    "# Rename the columns\n",
    "new_column_names = ['f' + str(i) for i in range(0, 24)] + ['class']\n",
    "df.columns = new_column_names\n",
    "\n",
    "eog_data = df\n",
    "emg_data = pd.read_csv('EMGF1.csv').values\n",
    "y_data = np.load('y_test_combined.npy')\n",
    "\n",
    "# Balance the datasets\n",
    "n_samples = min(len(eog_data), len(emg_data), len(y_data))\n",
    "\n",
    "eog_data_balanced = resample(eog_data, n_samples=n_samples, random_state=42)\n",
    "emg_data_balanced = resample(emg_data, n_samples=n_samples, random_state=42)\n",
    "y_data_balanced = resample(y_data, n_samples=n_samples, random_state=42)\n",
    "\n",
    "# Split balanced data into training and testing sets\n",
    "X_train_eog, X_test_eog, y_train, y_test = train_test_split(eog_data_balanced, y_data_balanced, test_size=0.2, random_state=42)\n",
    "X_train_emg, X_test_emg, y_train_emg, y_test_emg = train_test_split(emg_data_balanced, y_data_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert y_train and y_test for EOG data to one-hot encoded labels with 5 classes\n",
    "y_train_eog = to_categorical(np.clip(y_train - 1, 0, 4), num_classes=5)\n",
    "y_test_eog = to_categorical(np.clip(y_test - 1, 0, 4), num_classes=5)\n",
    "\n",
    "# Convert y_train and y_test for EMG data to one-hot encoded labels with 7 classes\n",
    "y_train_emg = to_categorical(y_train_emg, num_classes=7)\n",
    "y_test_emg = to_categorical(y_test_emg, num_classes=7)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_nn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(Dense(256, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Hidden layers\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model instances for EOG and EMG data\n",
    "eog_model = build_nn_model(X_train_eog.shape[1], num_classes=5)\n",
    "emg_model = build_nn_model(X_train_emg.shape[1], num_classes=7)\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train EOG model\n",
    "eog_model.fit(X_train_eog, y_train_eog, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Train EMG model\n",
    "emg_model.fit(X_train_emg, y_train_emg, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Save models\n",
    "eog_model.save('eog_nn_model.h5')\n",
    "emg_model.save('emg_nn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step\n",
      "22/22 [==============================] - 0s 744us/step\n",
      "Combined Model Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load trained models\n",
    "eog_model = tf.keras.models.load_model('eog_nn_model.h5')\n",
    "emg_model = tf.keras.models.load_model('emg_nn_model.h5')\n",
    "\n",
    "# Generate predictions\n",
    "eog_predictions = eog_model.predict(X_test_eog)\n",
    "emg_predictions = emg_model.predict(X_test_emg)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "eog_predictions = np.argmax(eog_predictions, axis=1) + 1  # Add 1 to match original class labels\n",
    "emg_predictions = np.argmax(emg_predictions, axis=1)\n",
    "\n",
    "# Stack predictions\n",
    "meta_features = np.column_stack((eog_predictions, emg_predictions))\n",
    "\n",
    "# Ensure y_test is one-hot encoded if necessary\n",
    "if len(y_test.shape) == 1:\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "# Convert y_test to class labels for meta-classifier\n",
    "y_test_meta = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Train meta-classifier\n",
    "meta_classifier = RandomForestClassifier(random_state=42)\n",
    "meta_classifier.fit(meta_features, y_test_meta)\n",
    "\n",
    "# Save meta-classifier\n",
    "with open('meta_classifier_rf.sav', 'wb') as file:\n",
    "    pickle.dump(meta_classifier, file)\n",
    "\n",
    "# Predict using meta-classifier\n",
    "final_predictions = meta_classifier.predict(meta_features)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test_meta, final_predictions)\n",
    "print(f'Combined Model Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
